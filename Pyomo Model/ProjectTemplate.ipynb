{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4c1e9d-502d-4d5f-8cfc-8c9224a8ea9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project report template\n",
    "\n",
    "Please use this template to report the status of your project to the instructor.<br>\n",
    "This cell contains some general instructions. It must not be present in your report,<br>\n",
    "\n",
    "**Instructions**\n",
    "- *Instructions are written in italics and must be removed from your report*\n",
    "- The markdown text formatting is an HTML dialect. You can use HTML commands to format your report. For example, use:\n",
    "    - \\<br\\> to wrap\n",
    "    - \\<!-- comment --\\> to insert an invisible comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477ee4c-c86e-468c-95ad-68dca285cbcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Title of the project\n",
    "\n",
    "Date: 28/03/2024 <br>\n",
    "Version: 1 <br>\n",
    "\n",
    "**Course**: Managerial Decision Making & Modeling\n",
    "\n",
    "**Investigator(s)**\n",
    "- Giuseppe Massidda , 901029@stud.unive.it\n",
    "- Lorenzo Muscillo , 1000916@stud.unive.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0996caf-704d-47f2-8d39-50ded86e32ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Document review(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a4b89-c097-41d9-bc6f-028a34409c77",
   "metadata": {},
   "source": [
    "*Fill in a cell like this one for each document review sent to the instructor.*\n",
    "\n",
    "Version: *Version of your document*\n",
    "- Modified sections: *List the sections that you have modified, e.g., All, or Model, or Scenatio 1*\n",
    "- Description/modifications: *A short description of your modifications, e.g., First draft, or Introduced new constraints, or introduced a new scenario*\n",
    "- Transmitted on date: *dd/mm/yyyy - Date you submitted this version of the report to the instructor*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523e769-6ad7-4f64-a52d-13516b2c4ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 - Abstract\n",
    "*A short summary, usually between 100 and 200 words.*<br>\n",
    "*Summarize this report's background, purpose, methodology, results, and conclusion.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25adff34-8bf1-4a9b-8946-98001bfec91f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 - Acronyms and definitions\n",
    "*Include this section if you use acronyms or technical terms in the text whose meaning may be unknown to the reader, may not correspond to the commonly understood meaning, or may otherwise be ambiguous.*\n",
    "\n",
    "*For example:*\n",
    "- *Unive: Università Ca' Foscari, Venice*.\n",
    "- *Facility: Warehouse with refrigerators dedicated to the storage of ice cream*.\n",
    "- *Distance: Great circle distance, i.e., as the crow flies, between two points*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c628c-6de1-4501-8ff4-2cd99e441b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 - Problem statement\n",
    "<hr>\n",
    "\n",
    "The board of Walmart Inc. commissioned an analysis of different scenarios of potential entry in the Italian market. The main issue that walmart faces when entering a different country relates to the cultural affinity of the customers for Walmart's brand and value proposition. For this reason, the board decided to start operating only in the Lombardia region. \n",
    "\n",
    "The goal of the operation is maximizing profits of the first twenty years.\n",
    "\n",
    "Profits are estimated by subtracting the initial investment expenses to the present value of the expected EBITDA (earnings before depreciation and amortization, margine operativo lordo) over the twenty years period. The initial investments will have to include the purchasing price of the properties as well as the costs associated with constructing the stores.\n",
    "\n",
    "The present value of future EBITDA over a long period can be calculated by first estimating a yearly EBITDA, and then adding together all the discounted values by a rate of 10%.\n",
    "\n",
    "In general, a store's EBITDA is proportional to its number of customers. People are less likely to go into a store if they live far away from it. However, larger stores will attract more customers than smaller ones.\n",
    "\n",
    "The board wants to know how many stores should be opened and where. The main challenge is finding suitable locations. A Walmart store is built on a large lot of land that has room for a large parking lot. For this reason empty lots are preferred to preexisting commercial buildings. Lots have to be within 20 and 60 thousands square meters.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3486283-a4bb-400a-91e9-1526a357a284",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 - System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7337557-5653-414a-8133-52fe53f5eee3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.1 - Agents/DMs\n",
    "*List the agents and DMs of interest to the problem.* <br>\n",
    "*Specify their attributes/characteristics (corresponding to the data to be collected) \n",
    "and, in the case of DMs, also their, possibly multiple, objectives.*\n",
    "<hr>\n",
    "The main decision maker is the company. Its objective is to place a number of stores in such a way that maximises profits.\n",
    "\n",
    "Customers are another agent of the system, they can be modeled as a population center (comune) that can be served by only one store.\n",
    "\n",
    "## 4.2 - Entities\n",
    "*List the entities of interest to the problem.* <br>\n",
    "*Specify their attributes/characteristics (corresponding to the data to be collected)*\n",
    "<hr>\n",
    "The potential lots to to be acquired are the key components of the system.\n",
    "Large commercial lots for sale on immobiliare.it will be considered. Data that has to be collected relates to the price, the location of the lot so that its distance from customers can be calculated.\n",
    "\n",
    "\n",
    "\n",
    "## 4.3 - Relationships among elements\n",
    "*List the relationships/interactions between the elements.*<br>\n",
    "*Specify their attributes/characteristics of interest to the problem (corresponding to the data to be collected) \n",
    "and the constraints they impose on the DMs' decisions.*\n",
    "<hr>\n",
    "A store EBITDA depends on the positioning of the stores, the closer a store is to a population center the higher it will be. EBITDA is also higher for larger stores.\n",
    "Costs are made up by two factors: a fixed cost that is the purchasing price of the lot, and a variable cost of construction that increases with the size of the store.\n",
    "\n",
    "## 4.4 - Other constituents of the system\n",
    "*List the possible external disturbances, internal uncertainties, externalities, \n",
    "and other components necessary to describe the system as a whole a\n",
    "and to understand the consequences of the DMs' decisions.*\n",
    "<hr>\n",
    "\n",
    "The success of such operation relies also on factors that are hard to model mathematically, for example cultural affinity of the customers for the brand and value proposition.\n",
    "\n",
    "Also there is a lot of uncertainty coming from the number of metrics that have to be estimated: average construction cost as a function of size; average share of a comune's population that can be attracted by a store as a function of its size and distance; average EBITDA as a function of the population attracted.\n",
    "\n",
    "## 4.5 - Assumptions\n",
    "*Clearly state any assumptions you make about the system, as in the following example:*<br>\n",
    "**Assumption**: *The demand for products decreases linearly with the price of the products.*\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Assumption**: EBITDA is linearly proportional to number of customers attracted.\n",
    "\n",
    "**Assumption**: A comune's entire population can be served only by one store.\n",
    "\n",
    "**Assumption**: The number of customers attracted by a store is:\n",
    "- decreasing in distance to the store.\n",
    "- increasing in the size of the store.\n",
    "\n",
    "**Assumption**: Costs are made up by two components:\n",
    "- the purchase price of the lot,\n",
    "- the construction costs, which are proportional to the lot size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741efcff-af2b-49a2-90da-499958a479b3",
   "metadata": {},
   "source": [
    "# 5 - Data\n",
    "\n",
    "- *List the data sources*\n",
    "- *Indicate the name of the csv/json/xlsx files that contain the data \n",
    "and provide a short describtion of how the data is organized* \n",
    "- *Clearly state possible assumptions, as in the following examples*\n",
    "\n",
    "**Assumption**: *Unit transportation cost data can be purchased from www.site.com. However, the data used in this project is artificially generated according to the following rule:*\n",
    "\n",
    "*unit transportation cost_{w,c} = 0.5 x great circle distance between warehouse w and customer c*\n",
    "\n",
    "\n",
    "**Assumption**: *The transportation costs are assumed as follows:*\n",
    "\n",
    "*unit transportation cost_{w,c} = alpha x distance between warehouse w and customer c*\n",
    "\n",
    "*fixed transportation cost_{w,c} = beta*\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Assumption**: lots can be purchased from many different channels, however we will consider only the ones listed for sale on immobiliare.it for which an address/coordinates as well as price and surface area are provided. We will use a web scraping script to download the data. We will use the openstreetmap overpass API to get the coordinates of a property from its address.\n",
    "\n",
    "Thus data on the lots/properties will be a data frame with four columns: price, area, latitude, longitude.\n",
    "\n",
    "**Assumption** We will assume the population is entirely concentrated in the center of the comune. Population data will be taken from ISTAT website. The customers data will be represented in a dataframe with all the comuni in the rows,  one column for population and two columns for latitude and longitude. Again the coordinates will be taken with an API query to openstreetmap.\n",
    "\n",
    "**Assumption** The earth is a perfect sphere, the distance between two points is the great circle distance calculated with the haversine function.\n",
    "\n",
    "\n",
    "**Assumption** The yearly EBITDA of a store is equal to the number of customers attracted times a constant that can be estimated looking at competitors. Esselunga in 2022 had 500 million EBITDA with 174 stores and 5 million customers who signed up for a fidelity card. https://www.esselunga.it/it-it/investor-relations/financial-information.html.\n",
    "\n",
    "Roughly 3 million EBITDA per store that has an average of 30 thousands customers. We will calculate yearly EBITDA for each store as 100€ times the number of customers.\n",
    "\n",
    "\n",
    "**Assumption** the number of customers from comune $C_i$ attracted by a store in $P_j$ is equal to $POP_i \\cdot f_1(dist(C_i,P_j)) \\cdot f_2(SIZE_j)$\n",
    "\n",
    "$f_1$ is a function $ dist \\mapsto [0,1]$ that gives the proportion of total population that considers being a customer of a store. As the distance increases, the proportion decresases.\n",
    "\n",
    "$f_2$ is a function $ SIZE_j \\mapsto [0,1]$ that gives the proportion of population that becomes a customer of a store, given its size. The larger the store the higher this proportion gets.\n",
    "\n",
    "We will assume that population at distance 0 will become customers with 30% probability. This probability will linearly decrease as it gets to 100 km, than it will be 0%.\n",
    "\n",
    " $f_1(dist) = \\max(0;0.3 - dist * 0.003)$\n",
    "\n",
    "$f_2$ will be modeled as 0.8 for the smallest possible property (20 thousands $m^2$), linearly increasing to 0.9 for the largest possible property (60 thousand $m^2$) \n",
    "\n",
    "$f_2(SIZE) = 0.75 + 0.0025 * SIZE$\n",
    "\n",
    "\n",
    "**Assumption** The cost of building a store in location P_j is the sum of the price and the construction cost, estimated as 1000€ per square meter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863ce2d-9271-45f6-ae45-9ea9bc62f601",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5 - Scenario 1\n",
    "*Fill in a section like this for each scenario*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef583b8-74e5-4d8a-baf3-344424dacbbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.1 - Mathematical model \n",
    "*Use this subsection to present the code of the main mathematical model for the considered problem*\n",
    "\n",
    "<hr>\n",
    "\n",
    "$C$ = Set of $n$ municipalities $\\cong \\{1,...,n\\}$ <br>\n",
    "$POP_{i}$ = Population of municipality for every $i \\in \\{1,\\dots,n\\}$ <br>\n",
    "\n",
    "$P$ = Set of $m$ Properties for sale<br>\n",
    "for every property we have $SIZE_j$ and $PRICE_j$ with $j \\in \\{1,...,m\\}$ \n",
    "\n",
    "\n",
    "For every pair $(C_i , P_j)$ we have a distance in km $dist_{i,j}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "*Decision Variables* <br>\n",
    "\n",
    "$y_j = \\{ 0;1 \\}$ if $P_j$ is choosen as a location to build a store\n",
    "\n",
    "$x_{i,j} = \\{ 0;1\\}$ if $P_{j}$ serves $C_i$\n",
    "<hr>\n",
    "\n",
    "We estimate the EBITDA of a store in property $P_j$ as:\n",
    "\n",
    "$EBITDA{j} = 100 € * \\sum^{n}_{i = 1} customers_{i,j} * x_{i_j}$\n",
    "\n",
    "where $customers_{i,j} = POP_i * \\max(0.3 - 0.003 * dist(C_i,P_j);0) * (0.75 + 0.0025*SIZE_j)$\n",
    "\n",
    "<hr>\n",
    "\n",
    "We estimate the cost of building a store in $P_j$ as\n",
    "\n",
    "$COST_{j} = y_j * (PRICE_j + (1000 * SIZE_j))$ <br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "The profits, the objective function to maximize will be\n",
    "\n",
    "$profits = \\sum_{j = 1}^m EBITDA_j - COST_j$\n",
    "\n",
    "<hr>\n",
    "\n",
    "The constraints are \n",
    "\n",
    "$\\sum_{j = 1}^m x_{i,j} \\le 1 \\quad \\quad \\forall i \\in \\{1,\\dots,n\\}$  each comune can be served by only one store\n",
    "\n",
    "$x_{i,j} \\le y_j \\quad \\quad \\forall i \\in \\{1,\\dots,n\\} \\quad \\forall j \\in \\{1,\\dots,m\\}$ comune $i$ can be served by store $j$ only if there is a store in $P_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e772f26-2115-43a5-89e2-5c9a690cb3cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.1 - Preliminary operations\n",
    "*Comment the code in the next cell that performs the preliminary operations, for example:*\n",
    "- *load libraries,* \n",
    "- *define functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd             \n",
    "import numpy as np              \n",
    "import math\n",
    "\n",
    "import json # JavaScript Object Notation encoding and decoding library\n",
    "\n",
    "import re # Regular expression operations library                     \n",
    "\n",
    "import requests # HTTP library for making requests                 \n",
    "\n",
    "import matplotlib.pyplot as plt # Plotting library\n",
    "\n",
    "from bs4 import BeautifulSoup # Library for pulling data out of HTML and XML files  \n",
    "\n",
    "import pyomo.environ as pyo # Python optimization modeling objects library    \n",
    "\n",
    "import folium # Library for creating interactive maps\n",
    "\n",
    "from IPython.display import display # Library for displaying objects in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d12fa1",
   "metadata": {},
   "source": [
    "## Weight for distances problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec973cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "little_com = df_prova.sample(n = 40)\n",
    "little_com = little_com[[\"Denominazione Comune\", \"Latitude\", \"Longitude\", \"distance\"]]\n",
    "\n",
    "\n",
    "little_ter = pd.DataFrame(data= {\"Title\" : [\"Via Casaglia, 25039 Travagliato BS\"],\n",
    "              \"Latitude\" : [45.516099],\n",
    "              \"Longitude\" : [10.089211]})\n",
    "\n",
    "def get_street_distance(origin_lat, origin_lon, dest_lat, dest_lon):\n",
    "    # OpenRouteService Directions API endpoint\n",
    "    url = \"https://api.openrouteservice.org/v2/directions/driving-car\"\n",
    "\n",
    "\n",
    "    api_key = \n",
    "\n",
    "    # Request headers\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json, application/geo+json, application/gpx+xml, img/png; charset=utf-8\",\n",
    "        \"Authorization\": api_key\n",
    "    }\n",
    "\n",
    "    # Request parameters\n",
    "    params = {\n",
    "        \"coordinates\": [[origin_lon, origin_lat], [dest_lon, dest_lat]],\n",
    "        \"units\": \"m\",\n",
    "        \"language\": \"en\",\n",
    "        \"instructions\": \"false\",\n",
    "        \"preference\": \"recommended\",\n",
    "        \"options\": {\n",
    "            \"avoid_features\": [\"tollways\", \"ferries\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.post(url, json=params, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        # Check if the request was successful and data is available\n",
    "        if response.status_code == 200 and \"routes\" in data and len(data[\"routes\"]) > 0:\n",
    "            distance_meters = data[\"routes\"][0][\"summary\"][\"distance\"]\n",
    "            distance_km = distance_meters / 1000  # Convert meters to kilometers\n",
    "            return distance_km\n",
    "        else:\n",
    "            # Handle error response or missing data\n",
    "            print(\"Error:\", data)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # Handle exceptions\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to calculate street distance and return it\n",
    "def calculate_street_distance(row):\n",
    "    street_distance = get_street_distance(row['Latitude'], row['Longitude'], 45.516099, 10.089211)\n",
    "    return street_distance\n",
    "\n",
    "# Apply the function to each row in little_com and store the results in a new column\n",
    "little_com['Street Distance'] = little_com.apply(calculate_street_distance, axis=1)\n",
    "\n",
    "# Display only the 'Street Distance' column\n",
    "little_com\n",
    "\n",
    "little_com[\"Difference\"] = (little_com[\"Street Distance\"] - little_com[\"distance\"])/little_com[\"distance\"]\n",
    "\n",
    "little_com[\"Difference\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bf00b-4188-474a-8bac-01cb6bd89524",
   "metadata": {},
   "source": [
    "### 5.1.2 - Sets\n",
    "*Comment the code in the next cell that defines the sets/lists needed to define the indexes of the model variables and constraints.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9fc31a",
   "metadata": {},
   "source": [
    "#### Getting data on properties for sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42502c8-108d-4750-93c4-c0ff31b2e346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Web scraping functions to search the informations that we need for the properties.\n",
    "\n",
    "# Function to get the BeautifulSoup object from a URL\n",
    "def get_soup(url, params=None, headers=None):\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "# Function to get the number of pages from the pagination section of the website\n",
    "def get_num_pages(url):\n",
    "    soup = get_soup(url)\n",
    "    pages_div = soup.find_all(\"div\", class_=\"in-pagination__item\")\n",
    "    pages_a = soup.find_all(\"a\", class_=\"in-pagination__item\")\n",
    "\n",
    "    pages_div = [page.text for page in pages_div]\n",
    "    pages_a = [page.text for page in pages_a]\n",
    "\n",
    "    num_list = list()\n",
    "    for page in pages_a + pages_div:\n",
    "        try:\n",
    "            num = int(page)\n",
    "            num_list.append(num)\n",
    "        except:\n",
    "            continue\n",
    "    return max(num_list)\n",
    "\n",
    "# Function to extract information about a single property listing from HTML\n",
    "def get_info_from_ad(ad):\n",
    "    title = ad.find(\"a\", class_=\"in-reListCard__title\").text\n",
    "    price = ad.find(\"div\", class_=\"in-reListCardPrice\").text\n",
    "    infos = ad.find_all(\"div\", class_=\"in-reListCardFeatureList__item\")\n",
    "    infos_text = [info.text for info in infos]\n",
    "    res = {\"title\": title, \"price\": price, \"infos\": infos_text}\n",
    "    return res\n",
    "\n",
    "# Function to scrape information about multiple property listings from a URL\n",
    "def get_immobiliare_info(url, params=None, headers=None):\n",
    "    soup = get_soup(url, params=params, headers=headers)\n",
    "    lands = soup.find_all(\"div\", class_=\"nd-mediaObject__content\")\n",
    "    res = []\n",
    "    for i, land in enumerate(lands):\n",
    "        res.append(get_info_from_ad(land))\n",
    "    return res\n",
    "\n",
    "# Function to retrieve information about all property listings in a specific region\n",
    "def get_all_from_region(region):\n",
    "    url = \"https://www.immobiliare.it/vendita-terreni/{}/?criterio=rilevanza&superficieMinima=20000&superficieMassima=60000&idTipologia=107\".format(\n",
    "        region)\n",
    "    url_with_page_num = url + \"&pag={}\"\n",
    "\n",
    "    num_pages = get_num_pages(url)\n",
    "    items = list()\n",
    "    for i in range(1, num_pages + 1):\n",
    "        items.extend(get_immobiliare_info(url_with_page_num.format(i)))\n",
    "    return items\n",
    "\n",
    "# Dictionary to store all property listings\n",
    "all_ads = dict()\n",
    "for region in [\"lombardia\"]:\n",
    "    all_ads[region] = get_all_from_region(region)\n",
    "\n",
    "# Print the number of lands found for each region\n",
    "for region in all_ads:\n",
    "    print(region, \"number of lands:\", len(all_ads[region]))\n",
    "\n",
    "# Save the results to a JSON file\n",
    "import json\n",
    "with open(\"ad.json\", 'w') as json_file:\n",
    "    json.dump(all_ads, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file containing property listings\n",
    "with open(\"ad.json\", \"r\") as json_file:\n",
    "    all_ads = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store property information\n",
    "streets = []\n",
    "prices = []\n",
    "titles = []\n",
    "surfaces = []\n",
    "\n",
    "# Loop through each region and its corresponding property listings\n",
    "for region, ads in all_ads.items():\n",
    "    for ad in ads:\n",
    "        title = ad[\"title\"]\n",
    "        price = ad[\"price\"]\n",
    "        surface = ad[\"infos\"]\n",
    "\n",
    "        streets.append(title)  # Append title to the streets list (not used further)\n",
    "        prices.append(price)   # Append price to the prices list\n",
    "        titles.append(title)   # Append title to the titles list\n",
    "        surfaces.append(surface)  # Append surface info to the surfaces list\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    \"Title\": titles,\n",
    "    \"Price\": prices,\n",
    "    \"Surface m^2\": surfaces\n",
    "}\n",
    "df_prop = pd.DataFrame(data)\n",
    "\n",
    "# Clean up the 'Title' column\n",
    "# Remove \"Terreno edificabile\" from the titles\n",
    "df_prop[\"Title\"] = df_prop[\"Title\"].str.replace(\"Terreno edificabile\", \"\")\n",
    "# Capitalize the first letter of each title\n",
    "df_prop[\"Title\"] = df_prop[\"Title\"].str.capitalize()\n",
    "\n",
    "# Remove rows containing \"Terreno residenziale\" or \"Prezzo\" in the 'Title' column\n",
    "df_prop = df_prop[~df_prop[\"Title\"].str.contains(\"Terreno residenziale\")]\n",
    "df_prop = df_prop[~df_prop[\"Price\"].str.contains(\"Prezzo\")]\n",
    "\n",
    "# Remove \"centro\" from the titles\n",
    "pattern = r'\\bcentro\\b'\n",
    "df_prop['Title'] = df_prop['Title'].str.replace(pattern, '', regex=True, case=False)\n",
    "\n",
    "# Capitalize the first letter of each title again\n",
    "df_prop['Title'] = df_prop['Title'].apply(capitalize_first_letter)\n",
    "\n",
    "# Function to extract and convert surface area to float\n",
    "def extract_and_convert_to_int(lst):\n",
    "    match = re.search(r'\\d+\\.\\d+', lst[0])\n",
    "    if match:\n",
    "        numeric_part = match.group()\n",
    "        return float(numeric_part)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Apply the function to the 'Surface m^2' column\n",
    "df_prop['Surface m^2'] = df_prop['Surface m^2'].apply(lambda x: extract_and_convert_to_int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representation of price to numerical value\n",
    "\n",
    "def string_to_num(string):\n",
    "    # Define the regex pattern to match numbers\n",
    "    pattern = r'\\d+'\n",
    "\n",
    "    # Find all matches in the string\n",
    "    matches = re.findall(pattern, string)\n",
    "    # Concatenate the matched digits\n",
    "    euro_amount = ''.join(matches)\n",
    "    return int(euro_amount)\n",
    "\n",
    "# Apply string_to_num function to convert 'Price' column to numerical values\n",
    "df_prop[\"Price\"] = df_prop[\"Price\"].apply(string_to_num)\n",
    "\n",
    "# Function to exclude outliers from a DataFrame column using the Interquartile Range (IQR) method\n",
    "def exclude_outliers(df, column_name, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Exclude possible outliers from a DataFrame column using the Interquartile Range (IQR) method.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame containing the column.\n",
    "        column_name (str): The name of the column containing the data.\n",
    "        threshold (float): The threshold value to determine outliers. Default is 1.5.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with outliers excluded.\n",
    "    \"\"\"\n",
    "    column = df[column_name]\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "    \n",
    "    # Exclude outliers\n",
    "    df_filtered = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Exclude outliers from the 'Price' column using the exclude_outliers function\n",
    "df_prop = exclude_outliers(df_prop, \"Price\")\n",
    "df_prop.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the web scraping we obtained the street but not the coordinates, so we create some function that\n",
    "# use an API from OpenStreetMap to get latitude and longitude.\n",
    "\n",
    "def get_coordinates(address):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {'q': address, 'format': 'json'}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            latitude = float(data[0]['lat'])\n",
    "            longitude = float(data[0]['lon'])\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "        return None, None\n",
    "\n",
    "df_prop['Latitude'], df_prop['Longitude'] = zip(*df_prop[\"Title\"].map(lambda x: get_coordinates(x)))\n",
    "df_prop.dropna(inplace=True)\n",
    "\n",
    "df_prop.reset_index(inplace = True, drop = True)\n",
    "df_prop.to_csv(\"df_prop.csv\")\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88005f8",
   "metadata": {},
   "source": [
    "#### Getting data on Comuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN\n",
    "# This queries the openstreetmap overpass API 1500 times\n",
    "# it gets all the coordinates for each comune in Lombardia\n",
    "\n",
    "df = pd.read_excel(\"Lombardia_tavole2021-Censimento-permanente.xlsx\", sheet_name=\"Tavola A1_COMUNI\", skiprows=2)\n",
    "df_pop = df[[\"PROVINCE\",\"Denominazione Comune\", \"Popolazione al 1° gennaio - Totale\"]]\n",
    "\n",
    "df_pop['Latitude'], df_pop['Longitude'] = zip(*df_pop[\"Denominazione Comune\"].map(lambda x: get_coordinates(x)))\n",
    "\n",
    "df_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75643730-4845-4471-8845-496975871020",
   "metadata": {},
   "source": [
    "### 5.1.3 - Parameters\n",
    "*Comment the code in the next cell that reads the data described in Section 5 and defines the dictionaries and/or frames used in the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cb211-6dfb-470f-873e-79f241a6fb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_prop = pd.read_csv(\"df_prop.csv\", index_col= 0)\n",
    "df_ter = pd.read_csv(\"pop.csv\")\n",
    "\n",
    "def calculate_distance_matrix(df_prop, df_ter):\n",
    "\n",
    "    # Now we need to calculate the distance matrix, that has \n",
    "    # the point to point distance between all 152 properties and all 1506 comuni.\n",
    "    # Note that 152 times 1506 = 228912\n",
    "\n",
    "    # Function for calculating distance\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        # Convert latitude and longitude from degrees to radians\n",
    "        lat1 = math.radians(lat1)\n",
    "        lon1 = math.radians(lon1)\n",
    "        lat2 = math.radians(lat2)\n",
    "        lon2 = math.radians(lon2)\n",
    "\n",
    "        # Haversine formula\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = (6371 * c)  # Radius of the Earth in kilometers \n",
    "\n",
    "        # Manhattan theorem\n",
    "\n",
    "        # distance = (abs(dlon)* 0.5) + (abs(dlat)*0.5)\n",
    "\n",
    "        return distance \n",
    "\n",
    "    # Using a list comprehension and a dict comprehension to calculate everything in a single line\n",
    "    distances = {j : \n",
    "                 [haversine(df_ter.loc[i,\"Latitude\"],df_ter.loc[i,\"Longitude\"],\n",
    "                            df_prop.loc[j,\"Latitude\"], df_prop.loc[j,\"Longitude\"]) \n",
    "                  for i in range(df_ter.shape[0])] \n",
    "                  for j in range(df_prop.shape[0])}\n",
    "\n",
    "    # Making it into a DataFrame\n",
    "    distances = pd.DataFrame(distances)\n",
    "    distances.columns.name = \"Comuni\"\n",
    "    distances.index.name = \"Properties\"\n",
    "    # Distances = distances.transpose()\n",
    "    return distances \n",
    "\n",
    "distances_matrix = calculate_distance_matrix(df_prop, df_ter)\n",
    "\n",
    "# Now that we have the distance matrix,\n",
    "# we can calculate the number of customers that\n",
    "# each property gets from each municipality\n",
    "# as we defined it, it's the product of 3 values, population, f_1(dist) and f_2(size)\n",
    "\n",
    "def plot_f1_f2(f1,f2):\n",
    "\n",
    "    x1 = np.linspace(0, 200, 100)  # Adjust the range and number of points as needed\n",
    "\n",
    "    # Generate x values for f2 (kilometers)\n",
    "    x2 = np.linspace(20, 60, 100)\n",
    "\n",
    "    # Calculate y values for each function\n",
    "    y1 = [f1(val) for val in x1]\n",
    "    y2 = [f2(val) for val in x2]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Adjust the figsize as needed\n",
    "\n",
    "    # Plot the functions\n",
    "    axs[0].plot(x1, y1, label='f1(x)')\n",
    "    axs[0].set_title('Function f1')\n",
    "    axs[0].set_xlabel('Distance, kilometers')\n",
    "    axs[0].set_ylabel('Probability of attracting a customer')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(x2, y2, label='f2(x)', color='orange')\n",
    "    axs[1].set_title('Function f2')\n",
    "    axs[1].set_xlabel('Size, thousands of square meters')\n",
    "    axs[1].set_ylabel('Probability of attracting a customer')\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_ebitda_matrix(df_prop = df_prop, df_ter = df_ter,yearly_ebitda_per_customer = 100,\n",
    "                  n_years_to_make_back_the_investment = 5, discount_rate = 0.05, distances = distances_matrix,\n",
    "                  f1 = lambda x: max(0, 0.3 - x * 0.003), f2 = lambda x: x* 0.0025 + 0.75):      \n",
    "\n",
    "       # Calculating f1: the fraction of customers that store j attract from comune i, given their distance\n",
    "       f_1_values = np.vectorize(f1)(np.asarray(distances))#(0.3 - np.asarray(distances) * 0.003)\n",
    "       # f_1_values[f_1_values < 0] = 0 #where it's negative we make it 0\n",
    "\n",
    "       print(\"checking that f1 is the interval [0,1]: \",\n",
    "              (f_1_values >= 0).sum().sum() == f_1_values.size & (f_1_values <= 1).sum().sum() == f_1_values.size)\n",
    "\n",
    "\n",
    "       # Calculating f2: the proportion of customers a store attracts given its size.\n",
    "       # We calculate this value for each store,\n",
    "       # then we turn it into a matrix by repeating the vector along the rows.\n",
    "       # This way the matrix is ready to by multiplied with the other matrices\n",
    "       f_2_values = np.vectorize(f2)(np.asarray(df_prop[\"Surface m^2\"]))\n",
    "       f_2_values = np.tile(f_2_values,(distances.shape[0],1))\n",
    "\n",
    "       print(\"checking that f2 is the interval [0,1]: \",\n",
    "              (f_2_values >= 0).sum().sum() == f_2_values.size & (f_2_values <= 1).sum().sum() == f_2_values.size)\n",
    "       plot_f1_f2(f1,f2)\n",
    "\n",
    "       # Now we make a population matrix, in a similar way that we did for f2 values\n",
    "       # the population is a vector, with one component for each municipality C,\n",
    "       # we repeat the vector many times, one per store so that we can multiply the matrices\n",
    "       pop_matrix = np.tile(np.asarray(df_ter.iloc[:,2]),(distances.shape[1],1)).T\n",
    "\n",
    "       # Calculating the number of customers that from municipality i will be a customer of a store in property j\n",
    "       customers_ij = pop_matrix * f_1_values * f_2_values\n",
    "       # Now just multiplying the number of customers times 100€ to calculate the yearly EBITDA\n",
    "\n",
    "       yearly_ebitda_ij = customers_ij * yearly_ebitda_per_customer\n",
    "       ebitda_ij = sum([yearly_ebitda_ij * (1+discount_rate)**-i for i in range(n_years_to_make_back_the_investment)]) \n",
    "       ''' La rendita anticipata segue la seguente formula V[0] = R * ((1-(1+i)^-n)/i) * (1+i) ora non so bene cosa\n",
    "       intendiamo noi come rendita, in alternativa ho scontato nella formula sopra l'ebitda, capiamo...'''\n",
    "\n",
    "       return ebitda_ij \n",
    "\n",
    "\n",
    "# Calculating the costs per each properties,\n",
    "# this is the cost vector that will be multiplied by the y_j variables\n",
    "def get_cost_vector(df_prop = df_prop, construction_cost = 1000):\n",
    "    price_j = df_prop.Price\n",
    "\n",
    "    # The construction cost is 1000 per square m, we have the data as thousands of square m\n",
    "    # we can just multipy it by 1000 so we get the construction cost in thousand of euros\n",
    "    construction_j = df_prop[\"Surface m^2\"] * construction_cost * 1000\n",
    "\n",
    "    cost_j = price_j + construction_j\n",
    "    return cost_j\n",
    "\n",
    "def get_coefficients(df_ter = df_ter, df_prop = df_prop, \n",
    "                     yearly_ebitda_per_customer = 100,\n",
    "                     n_years_to_make_back_the_investment = 5,\n",
    "                    discount_rate = 0.05,\n",
    "                    f1 = lambda x: max(0, 0.3 - x * 0.003),\n",
    "                    f2 = lambda x: x* 0.0025 + 0.75,\n",
    "                    construction_cost = 1000):\n",
    "    \n",
    "    distance_matrix = calculate_distance_matrix(df_prop, df_ter,)\n",
    "    ebitda_matrix = get_ebitda_matrix(df_prop = df_prop,\n",
    "                  df_ter = df_ter, \n",
    "                  yearly_ebitda_per_customer = yearly_ebitda_per_customer,\n",
    "                  n_years_to_make_back_the_investment = n_years_to_make_back_the_investment,\n",
    "                  discount_rate = discount_rate,\n",
    "                  distances = distance_matrix,\n",
    "                  f1 = f1,\n",
    "                  f2 = f2)\n",
    "    \n",
    "    cost_vector = get_cost_vector(df_prop = df_prop,\n",
    "                                  construction_cost = construction_cost) \n",
    "\n",
    "    # Define functions that take distance and parameters and calculate coefficients\n",
    "    return ebitda_matrix, cost_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be78828",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebitda, cost  = get_coefficients(df_ter = df_ter,\n",
    "                                 df_prop = df_prop, \n",
    "                                 yearly_ebitda_per_customer = 100,\n",
    "                                 n_years_to_make_back_the_investment = 20,\n",
    "                                 discount_rate = 0.1,\n",
    "                                 f1 = lambda x: max(0, 0.2 - x * 0.003),\n",
    "                                 f2 = lambda x: x * 0.0025 + 0.75,\n",
    "                                 construction_cost = 1000)\n",
    "\n",
    "ebitda, cost = pd.DataFrame(ebitda), pd.DataFrame(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d99bb-96e2-440b-98a2-f3d23e4f229a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.4 - Variables\n",
    "\n",
    "*Comment the code in the next cell that defines the variables of the model.*<br>\n",
    "*Specifically, indicate whether the variables are:*\n",
    "- *Decision variables, i.e., they model the DMs' decisions, or*\n",
    "- *Auxiliary variables, i.e., they are used, for example, to linearize the model objectives/constraints.*<br>\n",
    "*Specify the meaning and the nature (continuous, integer of binary) of each variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982286eb-e43d-4745-8218-a34ffb28f464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code that defines the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0e162-6479-437d-abf9-57887bc56330",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.5 - Constraints and Objective(s)\n",
    "*Comment the code in the next cell that defines the objectives and the constraints of the model.*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17af8cd-6da1-496d-ac8b-289e045688d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = pyo.ConcreteModel()\n",
    "\n",
    "num_y = cost.size\n",
    "\n",
    "num_rows, num_cols = ebitda.shape\n",
    "\n",
    "\n",
    "# Create x\n",
    "model.rows = pyo.RangeSet(1,num_rows)\n",
    "model.cols = pyo.RangeSet(1,num_cols)\n",
    "\n",
    "# Define decision variables\n",
    "model.x = pyo.Var(model.rows, model.cols, within = pyo.Binary)\n",
    "model.y = pyo.Var(range(1, num_y + 1), within = pyo.Binary)\n",
    "\n",
    "# Define the objective function programmatically\n",
    "def profit_function(model):\n",
    "    # Calculate total cost\n",
    "    cost_total = sum(model.y[j] * cost.iloc[j - 1, 0] for j in range(1, num_y + 1))\n",
    "\n",
    "    # Calculate total EBITDA\n",
    "    ebitda_total = sum(sum(ebitda.iloc[i - 1, j - 1] * model.x[i, j] for i in model.rows) for j in range(1, num_y + 1))\n",
    "\n",
    "    # Calculate profit\n",
    "    profit_total = ebitda_total - cost_total\n",
    "    return profit_total\n",
    "\n",
    "model.obj = pyo.Objective(rule = profit_function, sense = pyo.maximize)\n",
    "\n",
    "# Define constraints\n",
    "model.constraints = pyo.ConstraintList()\n",
    "for j in range(1, num_y + 1):\n",
    "    for i in range(1, num_rows + 1):\n",
    "        model.constraints.add(model.x[i,j] <= ebitda.iloc[i-1, j-1] * model.y[j])\n",
    "\n",
    "model.constraints2 = pyo.ConstraintList()\n",
    "for i in range(1,num_rows +1):\n",
    "    model.constraints2.add(sum(model.x[i,j] for j in range(1,num_cols+1)) <=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe00bb-b1f8-44d6-93fb-a9c0e5420b6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5.2 - Model solution\n",
    "*Comment the code in the next cell that calls the functions that solve the model and stores the values of the variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60964f84-5217-4dff-863f-43f8f6385ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('gurobi')\n",
    "results = solver.solve(model, tee = True)\n",
    "\n",
    "stores_to_open = dict()\n",
    "for j in range(1,num_y+1):\n",
    "    if pyo.value(model.y[j]) == 1:\n",
    "        print(j,pyo.value(model.y[j]))\n",
    "        print(\"Here are the comuni served by this store:\")\n",
    "        comuni_serviti = []\n",
    "        comuni_serviti_with_0_ebitda = []\n",
    "        for i in range(1, num_rows+1):\n",
    "            if pyo.value(model.x[i,j]) == 1:\n",
    "                if ebitda.iloc[i-1,j-1] > 1:\n",
    "                    comuni_serviti.append(i-1)\n",
    "                else: \n",
    "                    comuni_serviti_with_0_ebitda.append(i-1)\n",
    "        stores_to_open[j] = comuni_serviti\n",
    "        print(comuni_serviti)\n",
    "        print(len(comuni_serviti_with_0_ebitda),\"is the number of comuni serviti but provide 0 ebitda\")\n",
    "\n",
    "index_to_access = list(stores_to_open.keys())\n",
    "index_to_access = np.asarray(index_to_access)\n",
    "index_to_access = index_to_access -1\n",
    "\n",
    "n_comuni_serviti = {i-1 : len(comuni_serviti) for i, comuni_serviti in stores_to_open.items()}\n",
    "n_comuni_serviti = pd.Series(n_comuni_serviti, name = \"n_comuni\")\n",
    "\n",
    "result = df_prop.iloc[index_to_access].join(n_comuni_serviti)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2150b",
   "metadata": {},
   "source": [
    "### Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Municipalities served by stores\n",
    "def get_comuni_served_by_store(varj_index):\n",
    "# varj_index = 43\n",
    "\n",
    "    total_ebitda_from_comuni = ebitda[varj_index-1]\n",
    "    total_ebitda_from_comuni.name = \"ebitda\"\n",
    "    distance_from_store = distances_matrix[varj_index-1]\n",
    "    distance_from_store.name = \"distance\"\n",
    "    comuni_serviti_df = df_ter.iloc[stores_to_open[varj_index]].join(total_ebitda_from_comuni).join(distance_from_store).sort_values(by = \"ebitda\", ascending = False)\n",
    "    comuni_serviti_df.columns.name = result.Title.loc[varj_index -1]\n",
    "    return comuni_serviti_df\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "get_comuni_served_by_store(result.index[5]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221eeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_with_markers(locations):\n",
    "    mymap = folium.Map(location=[locations.iloc[0][\"Latitude\"], locations.iloc[0][\"Longitude\"]], zoom_start=7)\n",
    "    comuni_non_serviti = folium.FeatureGroup(name=\"Comuni non serviti\", show=False).add_to(mymap)\n",
    "    colors = ['lightred', 'blue', 'cadetblue', 'orange', 'lightblue', 'gray', 'pink', 'black', 'darkgreen', 'darkpurple', 'lightgray', 'green', 'white', 'beige', 'darkblue']\n",
    "    for iteration ,(i, row) in enumerate(locations.iterrows()):\n",
    "        town_feature_group = folium.FeatureGroup(name=row[\"Title\"], show=False).add_to(mymap)\n",
    "        folium.Marker([row[\"Latitude\"], row[\"Longitude\"]],popup=row[\"Title\"],icon=folium.Icon(color='red')).add_to(mymap)\n",
    "\n",
    "        comuni_serviti = get_comuni_served_by_store(int(i)+1)\n",
    "        for town_index,town in comuni_serviti.iterrows():\n",
    "            if town[\"ebitda\"] > 1:\n",
    "                folium.Marker([town[\"Latitude\"], town[\"Longitude\"]], popup=town[\"Denominazione Comune\"],icon=folium.Icon(color=colors[iteration])).add_to(town_feature_group)\n",
    "            else :\n",
    "                folium.Marker([town[\"Latitude\"], town[\"Longitude\"]], popup=town[\"Denominazione Comune\"],icon=folium.Icon(color='gray')).add_to(comuni_non_serviti)\n",
    "        town_feature_group.add_to(mymap)\n",
    "    comuni_non_serviti.add_to(mymap)\n",
    "    folium.LayerControl().add_to(mymap)\n",
    "    display(mymap)\n",
    "\n",
    "# Assuming `result` is a DataFrame with \"Latitude\" and \"Longitude\" columns\n",
    "locations = result[[\"Latitude\", \"Longitude\",\"Title\"]]\n",
    "\n",
    "create_map_with_markers(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343fc73-7514-4741-9d20-f191a01e823f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.3 - Analysis\n",
    "*Comment the model solutions and their possible applications in the real world with respect to different scenarios.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c989e8c",
   "metadata": {},
   "source": [
    "# 6 - Scenario 2\n",
    "\n",
    "The initial investment has to be under 50 million € so we add another constraint to apply a realistic situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyo.ConcreteModel()\n",
    "\n",
    "num_y = cost.size\n",
    "\n",
    "num_rows, num_cols = ebitda.shape\n",
    "\n",
    "\n",
    "# Create x\n",
    "model.rows = pyo.RangeSet(1,num_rows)\n",
    "model.cols = pyo.RangeSet(1,num_cols)\n",
    "\n",
    "# Define decision variables\n",
    "model.x = pyo.Var(model.rows, model.cols, within = pyo.UnitInterval)\n",
    "model.y = pyo.Var(range(1, num_y + 1), within = pyo.Binary)\n",
    "\n",
    "# Define the objective function programmatically\n",
    "def profit_function(model):\n",
    "    # Calculate total cost\n",
    "    cost_total = sum(model.y[j] * cost.iloc[j - 1, 0] for j in range(1, num_y + 1))\n",
    "\n",
    "    # Calculate total EBITDA\n",
    "    ebitda_total = sum(sum(ebitda.iloc[i - 1, j - 1] * model.x[i, j] for i in model.rows) for j in range(1, num_y + 1))\n",
    "\n",
    "    # Calculate profit\n",
    "    profit_total = ebitda_total - cost_total\n",
    "    return profit_total\n",
    "\n",
    "model.obj = pyo.Objective(rule = profit_function, sense = pyo.maximize)\n",
    "\n",
    "# Define constraints\n",
    "model.constraints = pyo.ConstraintList()\n",
    "for j in range(1, num_y + 1):\n",
    "    for i in range(1, num_rows + 1):\n",
    "        model.constraints.add(model.x[i,j] <= ebitda.iloc[i-1, j-1] * model.y[j])\n",
    "\n",
    "model.constraints2 = pyo.ConstraintList()\n",
    "for i in range(1,num_rows +1):\n",
    "    model.constraints2.add(sum(model.x[i,j] for j in range(1,num_cols+1)) <=1)\n",
    "\n",
    "max_total_cost = 50000000 \n",
    "\n",
    "# Add constraint for maximum total cost\n",
    "model.constraints3 = pyo.ConstraintList()\n",
    "model.constraints.add(sum(model.y[j] * cost.iloc[j - 1, 0] for j in range(1, num_y + 1)) <= max_total_cost)\n",
    "\n",
    "\n",
    "## Solver\n",
    "solver = pyo.SolverFactory('gurobi')\n",
    "results = solver.solve(model, tee = True)\n",
    "\n",
    "## Results\n",
    "\n",
    "stores_to_open = dict()\n",
    "for j in range(1,num_y+1):\n",
    "    if pyo.value(model.y[j]) == 1:\n",
    "        print(j,pyo.value(model.y[j]))\n",
    "        print(\"Here are the comuni served by this store:\")\n",
    "        comuni_serviti = []\n",
    "        for i in range(1, num_rows+1):\n",
    "            if pyo.value(model.x[i,j]) > 0:\n",
    "                comuni_serviti.append(i)\n",
    "        stores_to_open[j] = comuni_serviti\n",
    "        print(comuni_serviti)\n",
    "\n",
    "index_to_access = list(stores_to_open.keys())\n",
    "index_to_access = np.asarray(index_to_access)\n",
    "index_to_access = index_to_access + 1\n",
    "\n",
    "n_comuni_serviti = {i+1 : len(comuni_serviti) for i, comuni_serviti in stores_to_open.items()}\n",
    "n_comuni_serviti = pd.Series(n_comuni_serviti, name = \"n\")\n",
    "\n",
    "df_prop.iloc[index_to_access].join(n_comuni_serviti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb205f4",
   "metadata": {},
   "source": [
    "## 6.2 - Model solution\n",
    "*Comment the code in the next cell that calls the functions that solve the model and stores the values of the variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('gurobi')\n",
    "results = solver.solve(model, tee = True)\n",
    "\n",
    "stores_to_open = dict()\n",
    "for j in range(1,num_y+1):\n",
    "    if pyo.value(model.y[j]) == 1:\n",
    "        print(j,pyo.value(model.y[j]))\n",
    "        print(\"Here are the comuni served by this store:\")\n",
    "        comuni_serviti = []\n",
    "        comuni_serviti_with_0_ebitda = []\n",
    "        for i in range(1, num_rows+1):\n",
    "            if pyo.value(model.x[i,j]) == 1:\n",
    "                if ebitda.iloc[i-1,j-1] > 1:\n",
    "                    comuni_serviti.append(i-1)\n",
    "                else: \n",
    "                    comuni_serviti_with_0_ebitda.append(i-1)\n",
    "        stores_to_open[j] = comuni_serviti\n",
    "        print(comuni_serviti)\n",
    "        print(len(comuni_serviti_with_0_ebitda),\"is the number of comuni serviti but provide 0 ebitda\")\n",
    "\n",
    "index_to_access = list(stores_to_open.keys())\n",
    "index_to_access = np.asarray(index_to_access)\n",
    "index_to_access = index_to_access -1\n",
    "\n",
    "n_comuni_serviti = {i-1 : len(comuni_serviti) for i, comuni_serviti in stores_to_open.items()}\n",
    "n_comuni_serviti = pd.Series(n_comuni_serviti, name = \"n_comuni\")\n",
    "\n",
    "result = df_prop.iloc[index_to_access].join(n_comuni_serviti)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c4046",
   "metadata": {},
   "source": [
    "### Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Municipalities served by stores\n",
    "def get_comuni_served_by_store(varj_index):\n",
    "# varj_index = 43\n",
    "\n",
    "    total_ebitda_from_comuni = ebitda[varj_index-1]\n",
    "    total_ebitda_from_comuni.name = \"ebitda\"\n",
    "    distance_from_store = distances_matrix[varj_index-1]\n",
    "    distance_from_store.name = \"distance\"\n",
    "    comuni_serviti_df = df_ter.iloc[stores_to_open[varj_index]].join(total_ebitda_from_comuni).join(distance_from_store).sort_values(by = \"ebitda\", ascending = False)\n",
    "    comuni_serviti_df.columns.name = result.Title.loc[varj_index -1]\n",
    "    return comuni_serviti_df\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "get_comuni_served_by_store(result.index[5]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50db5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_with_markers(locations):\n",
    "    mymap = folium.Map(location=[locations.iloc[0][\"Latitude\"], locations.iloc[0][\"Longitude\"]], zoom_start=7)\n",
    "    comuni_non_serviti = folium.FeatureGroup(name=\"Comuni non serviti\", show=False).add_to(mymap)\n",
    "    colors = ['lightred', 'blue', 'cadetblue', 'orange', 'lightblue', 'gray', 'pink', 'black', 'darkgreen', 'darkpurple', 'lightgray', 'green', 'white', 'beige', 'darkblue']\n",
    "    for iteration ,(i, row) in enumerate(locations.iterrows()):\n",
    "        town_feature_group = folium.FeatureGroup(name=row[\"Title\"], show=False).add_to(mymap)\n",
    "        folium.Marker([row[\"Latitude\"], row[\"Longitude\"]],popup=row[\"Title\"],icon=folium.Icon(color='red')).add_to(mymap)\n",
    "\n",
    "        comuni_serviti = get_comuni_served_by_store(int(i)+1)\n",
    "        for town_index,town in comuni_serviti.iterrows():\n",
    "            if town[\"ebitda\"] > 1:\n",
    "                folium.Marker([town[\"Latitude\"], town[\"Longitude\"]], popup=town[\"Denominazione Comune\"],icon=folium.Icon(color=colors[iteration])).add_to(town_feature_group)\n",
    "            else :\n",
    "                folium.Marker([town[\"Latitude\"], town[\"Longitude\"]], popup=town[\"Denominazione Comune\"],icon=folium.Icon(color='gray')).add_to(comuni_non_serviti)\n",
    "        town_feature_group.add_to(mymap)\n",
    "    comuni_non_serviti.add_to(mymap)\n",
    "    folium.LayerControl().add_to(mymap)\n",
    "    display(mymap)\n",
    "\n",
    "# Assuming `result` is a DataFrame with \"Latitude\" and \"Longitude\" columns\n",
    "locations = result[[\"Latitude\", \"Longitude\",\"Title\"]]\n",
    "\n",
    "create_map_with_markers(locations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
